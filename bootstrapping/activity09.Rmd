---
title: "Activity 9 - Bootstrapping"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load the necessary packages
```{r}
library(tidyverse)
library(tidymodels)
library(tibble)
library(dplyr)
library(ggplot2)
library(GGally)
```
## Create the data
To help conceptualize bootstrapping to traditional methods that we explore earlier this semester, we will create our own dataset. This way, we will know the truth about the population from which we are drawing data and can compare how bootstrapping and the traditional methods compare (and are different).
```{r}
# Set a random seed value so we can obtain the same "random" results
set.seed(2023)

# Create a data frame/tibble named sim_dat
sim_dat <- tibble(
#  creates a vector named x1 containing 20 random numbers, each between -5 (min) and 5(max).
  x1 = runif(20, -5, 5),
#  creates a vector named x2 containing 20 random numbers, each between 0 (min) and 100(max).
  x2 = runif(20, 0, 100),
# creates a vector named x3 containing 20 random numbers, each of which is either 0 or 1, with a 50% probability for each outcome. This essentially generates 20 random Bernoulli trials with equal probability for success (1) and failure (0)
  x3 = rbinom(20, 1, 0.5)
  )

b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5

errors <- rnorm(20, 0, sigma)

sim_dat <- sim_dat %>% 
  mutate(
    y = b0 + b1*x1 + b2*x2 + b3*x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
      )
    )
```
What is the true (population-level) model? Note that we are adding noise/variability, but based on the above code you can see what the “baseline” model is.

y=2+0.25⋅x1−0.5⋅x2+1⋅x3

Create graphical visualizations for the relationship between all variable pairs (i.e., y and each x and also each x pair). 

Provide a brief summary of what you see/notice. That is, how do these relationships compare with your comments from (1) and model in (2)? Especially for the relationship between y and each x. 

```{r, message=FALSE}
# Set a random seed for reproducibility
set.seed(2023)

# Create the data frame/tibble named sim_dat
sim_dat <- tibble(
  x1 = runif(20, -5, 5),
  x2 = runif(20, 0, 100),
  x3 = rbinom(20, 1, 0.5)
)

# Define the coefficients and error standard deviation
b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5

# Generate errors
errors <- rnorm(20, 0, sigma)

# Create the dependent variable y and transform x3
sim_dat <- sim_dat %>%
  mutate(
    y = b0 + b1 * x1 + b2 * x2 + b3 * x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
    )
  )

# Create the pairs plot using ggpairs
ggpairs(sim_dat)

```
This code will produce a pairs plot matrix for all variable pairs in the sim_dat dataset. Here’s a brief summary of what you might see:

y vs. x1: Given the true model 

y=2+0.25⋅x1−0.5⋅x2+1⋅x3+error, you should see a positive linear relationship between 
y vs. x2: You should observe a negative linear relationship between x2, again with some scatter due to the error term.

y vs. x3: Since x3 is a binary variable, you should see two clusters of points corresponding to x3=0 ("No") and x3=1 ("Yes"). The cluster for x3=1 should be shifted upward by approximately 1 unit on the y-axis compared to the cluster for x3=0.

x1 vs. x2: Since x1 and x2 are both uniformly distributed random variables, there should be no clear relationship or pattern between these two variables.

x1 vs. x3 and x2 vs. x3: Similarly, there should be no clear relationship between x1 or x2 and x3 as 
x3 is a binary variable and x1 and x2 are uniformly distributed random variables.

## Traditional MLR model
First we will fit an estimated model to our simulated data.
```{r}
mlr_fit <- linear_reg() %>%
  set_mode("regression") %>% 
  set_engine("lm") %>% 
  fit(y ~ x1 + x2 + x3, data = sim_dat)

# Also include the confidence intervals for our estimated slope parameters
tidy(mlr_fit, conf.int = TRUE)
```
The results from fitting the linear model indicate the following:

Intercept (estimate = 1.9421859, std.error = 0.75619115):

The intercept is approximately 1.94, which is close to the true value of 2 specified in the population-level model. The standard error is about 0.76, indicating the variability of this estimate.
x1 (estimate = 0.3347926, std.error = 0.08911603):

The coefficient for x1 is approximately 0.33, which is slightly higher than the true value of 0.25. The standard error is about 0.089, suggesting a relatively precise estimate.
x2 (estimate = -0.4953973, std.error = 0.01084670):

The coefficient for x2 is approximately -0.50, which is very close to the true value of -0.5. The standard error is about 0.011, indicating a very precise estimate.
x3Yes (estimate = 1.8142189, std.error = 0.50919353):

The coefficient for x3 (when x3 is "Yes") is approximately 1.81, which is higher than the true value of 1. The standard error is about 0.51, indicating some variability in this estimate.

Summary of Relationships
y vs. x1: The fitted coefficient (0.33) is slightly higher than the true value (0.25). This indicates a positive linear relationship between y and x1, aligning with the expected relationship in the true model.

y vs. x2: The fitted coefficient (-0.50) is almost identical to the true value (-0.5). This indicates a negative linear relationship between y and x2, matching the expected relationship in the true model.

y vs. x3: The fitted coefficient (1.81) for x3 when it is "Yes" is higher than the true value (1). This suggests that y increases by approximately 1.81 units when x3 changes from "No" to "Yes". The true model expected an increase of 1 unit, so this relationship is slightly stronger than anticipated.

The visualizations would confirm these relationships by showing:

y vs. x1: A positive linear trend, though some scatter will be present due to the error term.
y vs. x2: A negative linear trend, with scatter due to the error term.
y vs. x3: Two distinct clusters, with the "Yes" cluster having higher y values compared to the "No" cluster.
x1 vs. x2: No discernible pattern, as both are uniformly distributed.
x1 vs. x3 and x2 vs. x3: No clear relationship, as 
x3 is binary and x1 and x2 are uniformly distributed.

These observations and the fitted model coefficients confirm the expected relationships specified in the population-level model, with minor variations likely due to random noise.

## Bootstrapping
Now, bootstrapping treats your sample of data as a psuedo-population that you will create multiple new samples from. Each sample will be of the same size and same number of variables as the original (
n=20, p=3). However, once a row has been sampled, it will be put back into the “population” (i.e., sampling with replacement). With computing power being relatively cheap now, we can do this for a large number of times to build up B bootstrap samples. For example, we might do B=2,000 bootstrap samples each of n=20
.
```{r}
# Set a random seed value so we can obtain the same "random" results
set.seed(631)

# Generate the 2000 bootstrap samples
boot_samps <- sim_dat %>% 
  bootstraps(times = 2000)

boot_samps
```
When viewing this outputted object, it probably looks a little odd. This is a nested data set with two columns:

splits: An rsplit object that has two main components: an analysis dataset and an assessment dataset.
id: A label of which bootstrap sample it is.

Now we need to fit a linear model to each bootstrap sample. Hopefully, from STA 518, you remember some of the handy iteration functions from {purrr}.
```{r}
# Create a function that fits a fixed MLR model to one split dataset
fit_mlr_boots <- function(split) {
  lm(y ~ x1 + x2 + x3, data = analysis(split))
}

# Fit the model to each split and store the information
# Also, obtain the tidy model information
boot_models <- boot_samps %>% 
  mutate(
    model = map(splits, fit_mlr_boots),
    coef_info = map(model, tidy)
    )

boots_coefs <- boot_models %>% 
  unnest(coef_info)

boots_coefs
```
We can then calculate the bootstrap intervals by obtaining the 2.5th and 97.5th percentiles - similar to a 95% confidence interval as we are finding the values that contain the middle 95% of the bootstrap values. Note that we provide the level of significance (1 - confidence level): alpha=0.05 = 1-0.95

```{r}
boot_int <- int_pctl(boot_models, statistics = coef_info, alpha = 0.05)
boot_int
```
visualize this information to get a sense of the variability of my estimates.
```{r}
ggplot(boots_coefs, aes(x = estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(data = boot_int, aes(xintercept = .lower), col = "blue") +
  geom_vline(data = boot_int, aes(xintercept = .upper), col = "blue")
```


To assess the accuracy of the fitted model compared to the population-level model, we can compare the confidence intervals for each coefficient with the true values from the population-level model. 

Population-Level Model Coefficients
Intercept: b0=2
x1: b1=0.25
x2: b2=−0.5
x3: b3=1

Fitted Model Results and Confidence Intervals
Intercept:
Estimate: 1.9328480
95% Confidence Interval: [0.1756609, 1.9328480]
x1:
Estimate: 0.3399160
95% Confidence Interval: [0.1896967, 0.3399160]
x2:
Estimate: -0.4950271
95% Confidence Interval: [-0.5162847, -0.4950271]
x3:
Estimate: 1.8262014
95% Confidence Interval: [0.8921258, 1.8262014]

The accuracy of the model coefficients can be summarized as follows:

The intercept estimate (1.9328480) is close to the true value (2) but not within the 95% CI, indicating slight inaccuracy.
The estimate for x1 (0.3399160) is close to the true value (0.25) and within the 95% CI, indicating good accuracy.
The estimate for x2 (-0.4950271) is very close to the true value (-0.5) and within the 95% CI, indicating high accuracy.
The estimate for x3 (1.8262014) is higher than the true value (1) but not within the 95% CI, indicating some inaccuracy.
These conclusions were made by comparing the true population-level coefficients with the estimated coefficients and their respective confidence intervals from the fitted model. This approach allows us to evaluate how well the model estimates match the true values and assess the precision of these estimates.

## Challenge

Add a pair of vertical orange lines that correspond to the traditional method’s 95% confidence intervals
A single vertical blue line that corresponds to the population slope value (there should be a unique blue line in each plot)
```{r}

# Set a random seed for reproducibility
set.seed(2023)

# Create the data frame/tibble named sim_dat
sim_dat <- tibble(
  x1 = runif(20, -5, 5),
  x2 = runif(20, 0, 100),
  x3 = rbinom(20, 1, 0.5)
)

# Define the coefficients and error standard deviation
b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5

# Generate errors
errors <- rnorm(20, 0, sigma)

# Create the dependent variable y and transform x3
sim_dat <- sim_dat %>%
  mutate(
    y = b0 + b1 * x1 + b2 * x2 + b3 * x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
    )
  )

# Fit a linear model
model <- lm(y ~ x1 + x2 + x3, data = sim_dat)
summary(model)

# Extract coefficients and confidence intervals
coef_df <- data.frame(
  term = names(coef(model)),
  estimate = coef(model),
  lower = confint(model)[, 1],
  upper = confint(model)[, 2]
)

# Define true values
true_values <- data.frame(
  term = c("(Intercept)", "x1", "x2", "x3Yes"),
  value = c(b0, b1, b2, b3)
)

# Plotting the coefficients with confidence intervals and true values
ggplot(coef_df, aes(x = term, y = estimate)) +
  geom_point(size = 3, color = "red") +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2, color = "orange") +
  geom_vline(data = true_values, aes(xintercept = term, yintercept = value), color = "blue", linetype = "dashed") +
  labs(title = "Estimated Coefficients with Confidence Intervals",
       x = "Term",
       y = "Estimate") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12)) +
  scale_color_manual(values = c("red", "orange", "blue")) +
  scale_fill_manual(values = c("red", "orange", "blue"))



```
Adding a line to show 